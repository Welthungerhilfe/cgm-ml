{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-28 23:01:04--  https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/multi_person_mobilenet_v1_075_float.tflite\n",
      "Resolving storage.googleapis.com... 172.217.168.240, 2a00:1450:400e:80d::2010\n",
      "Connecting to storage.googleapis.com|172.217.168.240|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5048148 (4.8M) [application/octet-stream]\n",
      "Saving to: ‘multi_person_mobilenet_v1_075_float.tflite.1’\n",
      "\n",
      "multi_person_mobile 100%[===================>]   4.81M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2019-03-28 23:01:04 (58.5 MB/s) - ‘multi_person_mobilenet_v1_075_float.tflite.1’ saved [5048148/5048148]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install glob2\n",
    "!wget https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/multi_person_mobilenet_v1_075_float.tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob2\n",
    "import os\n",
    "from random import randint\n",
    "from IPython.core.display import Image, display\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from skimage import transform,io\n",
    "#import PIL\n",
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpg_paths 97\n"
     ]
    }
   ],
   "source": [
    "training_path = \"/whhdata/person/MH_WHH_0153/measurements/1537860868501/rgb/\"\n",
    "glob_search_path = os.path.join(training_path, \"**/*.jpg\")\n",
    "jpg_paths = glob2.glob(glob_search_path)\n",
    "print(\"jpg_paths\", len(jpg_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 36: /whhdata/person/MH_WHH_0153/measurements/1537860868501/rgb/rgb_MH_WHH_0153_1537860868501_104_95409.57449405201.jpg\n"
     ]
    }
   ],
   "source": [
    "index = randint(0,len(jpg_paths)-1)\n",
    "img_filename = jpg_paths[index]\n",
    "print(\"File %s: %s\" % (index, img_filename))\n",
    "#display(Image(filename=img_filename, width=257, height=353))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n",
      "(1920, 1080, 3)\n",
      "(1, 353, 257, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py36/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "image = io.imread(img_filename)\n",
    "print(image.shape)\n",
    "image_rot = transform.rotate(image,90.0,resize=True)\n",
    "print(image_rot.shape)\n",
    "small_input = transform.resize(image_rot,(353,257), mode='symmetric', preserve_range=True)\n",
    "# reshape to (1,784)\n",
    "\n",
    "reshape_img = small_input.reshape(1, 353,257, 3)\n",
    "print(reshape_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 353 257   3]\n",
      "[{'name': 'sub_2', 'index': 97, 'shape': array([  1, 353, 257,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\n",
      "(1, 23, 17, 17)\n"
     ]
    }
   ],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.contrib.lite.Interpreter(model_path=\"./multi_person_mobilenet_v1_075_float.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "print(input_shape)\n",
    "print(interpreter.get_input_details())\n",
    "\n",
    "input_data = np.array(reshape_img, dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data.shape)\n",
    "#print(output_data[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    import cv2\n",
    "    import IPython\n",
    "    _,ret = cv2.imencode('.jpg', img) \n",
    "    i = IPython.display.Image(data=ret)\n",
    "    IPython.display.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import PIL.Image\n",
    "#from cStringIO import StringIO\n",
    "import io\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "def showarray(a, fmt='png'):\n",
    "    a = np.uint8(a)\n",
    "    f = io.StringIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    IPython.display.display(IPython.display.Image(data=f.getvalue()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIL.Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#imshow(small_input)\n",
    "#imshow(image_rot)\n",
    "#imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
