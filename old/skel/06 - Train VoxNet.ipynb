{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VoxNet (http://dimatura.net/research/voxnet/).\n",
    "\n",
    "This notebook shows you how to use the ETLDataGenerator in order to train VoxNet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset path.\n",
    "\n",
    "This snippet shows you how to get the lates preprocessed path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! VTK not available. This might limit the functionality.\n",
      "Using dataset path ../../data/etl/2018_10_31_14_19_42\n"
     ]
    }
   ],
   "source": [
    "from cgmcore.etldatagenerator import get_dataset_path\n",
    "\n",
    "dataset_path = get_dataset_path(\"../../data/etl\")\n",
    "print(\"Using dataset path\", dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 10\n",
    "validation_steps = 10\n",
    "epochs = 4\n",
    "batch_size = 1\n",
    "random_seed = 667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data-generator.\n",
    "\n",
    "The method create_datagenerator_from_parameters is a convencience method. It allows you to instantiate a generator from a specification-dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data-generator...\n"
     ]
    }
   ],
   "source": [
    "from cgmcore.etldatagenerator import create_datagenerator_from_parameters\n",
    "\n",
    "dataset_parameters_voxelgrids = {}\n",
    "dataset_parameters_voxelgrids[\"input_type\"] = \"voxelgrid\"\n",
    "dataset_parameters_voxelgrids[\"output_targets\"] = [\"height\"]\n",
    "dataset_parameters_voxelgrids[\"random_seed\"] = random_seed\n",
    "dataset_parameters_voxelgrids[\"voxelgrid_target_shape\"] = (32, 32, 32)\n",
    "dataset_parameters_voxelgrids[\"voxel_size_meters\"] = 0.1\n",
    "dataset_parameters_voxelgrids[\"voxelgrid_random_rotation\"] = False\n",
    "dataset_parameters_voxelgrids[\"sequence_length\"] = 0\n",
    "datagenerator_instance_voxelgrids = create_datagenerator_from_parameters(dataset_path, dataset_parameters_voxelgrids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the QR-Codes and do a train-validate-split.\n",
    "\n",
    "The data-generator is perfectly capable of retrieving all QR-codes from the dataset. This snippet shows how to do so and how to split the QR-codes into two sets: Train and validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QR-codes for training:\n",
      " MH_WHH_0001\tMH_WHH_0003\tMH_WHH_0004\tMH_WHH_0009\tMH_WHH_0010\tMH_WHH_0014\tMH_WHH_0016\tMH_WHH_0017\tMH_WHH_0019\tMH_WHH_0022\tMH_WHH_0028\tMH_WHH_0036\tMH_WHH_0044\tMH_WHH_0054\tMH_WHH_0063\tMH_WHH_0075\tMH_WHH_0076\tMH_WHH_0081\tMH_WHH_0082\tMH_WHH_0083\tMH_WHH_0095\tMH_WHH_0096\tMH_WHH_0102\tMH_WHH_0104\n",
      "QR-codes for validation:\n",
      " MH_WHH_0008\tMH_WHH_0027\tMH_WHH_0030\tMH_WHH_0056\tMH_WHH_0077\tMH_WHH_0097\n"
     ]
    }
   ],
   "source": [
    "# Get the QR-codes.\n",
    "qrcodes_to_use = datagenerator_instance_voxelgrids.qrcodes[0:30]\n",
    "\n",
    "# Do the split.\n",
    "random.seed(random_seed)\n",
    "qrcodes_shuffle = qrcodes_to_use[:]\n",
    "random.shuffle(qrcodes_shuffle)\n",
    "split_index = int(0.8 * len(qrcodes_shuffle))\n",
    "qrcodes_train = sorted(qrcodes_shuffle[:split_index])\n",
    "qrcodes_validate = sorted(qrcodes_shuffle[split_index:])\n",
    "del qrcodes_shuffle\n",
    "print(\"QR-codes for training:\\n\", \"\\t\".join(qrcodes_train))\n",
    "print(\"QR-codes for validation:\\n\", \"\\t\".join(qrcodes_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating python generators for training and validation.\n",
    "\n",
    "Now both QR-codes lists can be used for creating the actual generators. One for training and one for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create python generators.\n",
    "generator_voxelgrids_train = datagenerator_instance_voxelgrids.generate(size=batch_size, qrcodes_to_use=qrcodes_train)\n",
    "generator_voxelgrids_validate = datagenerator_instance_voxelgrids.generate(size=batch_size, qrcodes_to_use=qrcodes_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the generator to create data manually.\n",
    "\n",
    "Of course you can use the generator to create data manually anytime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input-shape: (1, 32, 32, 32)\n",
      "Output-shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = next(generator_voxelgrids_train)\n",
    "print(\"Input-shape:\", train_x.shape)\n",
    "print(\"Output-shape:\", train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training-details.\n",
    "\n",
    "Training-details are a dictionary that gets stored in a file after training. It is supposed to contain information that is valuable. For example data that is relevant for training including the hyper-parameters. Intended to be used when comparing different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_details = {\n",
    "    \"dataset_path\" : dataset_path,\n",
    "    \"qrcodes_train\" : qrcodes_train,\n",
    "    \"qrcodes_validate\" : qrcodes_validate,\n",
    "    \"steps_per_epoch\" : steps_per_epoch,\n",
    "    \"validation_steps\" : validation_steps,\n",
    "    \"epochs\" : epochs,\n",
    "    \"batch_size\" : batch_size,\n",
    "    \"random_seed\" : random_seed,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training VoxNet.\n",
    "\n",
    "The module modelutils contains methods for creating Neural Nets. The following code shows how to instantiate and train VoxNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 32, 32, 32, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 14, 14, 14, 32)    4032      \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 12, 12, 12, 32)    27680     \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 6, 6, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               884864    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 916,705\n",
      "Trainable params: 916,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      "10/10 [==============================] - 9s 870ms/step - loss: 4821.9994 - mean_absolute_error: 59.2308 - val_loss: 165.7682 - val_mean_absolute_error: 11.1273\n",
      "Epoch 2/4\n",
      "10/10 [==============================] - 5s 519ms/step - loss: 230.6424 - mean_absolute_error: 12.3561 - val_loss: 280.3506 - val_mean_absolute_error: 13.2093\n",
      "Epoch 3/4\n",
      " 3/10 [========>.....................] - ETA: 1s - loss: 191.2405 - mean_absolute_error: 11.2892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.198777). Check your callbacks.\n",
      "  % delta_t_median)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.100669). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 552ms/step - loss: 129.9065 - mean_absolute_error: 9.9358 - val_loss: 215.1790 - val_mean_absolute_error: 11.2353\n",
      "Epoch 4/4\n",
      " 1/10 [==>...........................] - ETA: 1s - loss: 987.0907 - mean_absolute_error: 31.4180"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.172569). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 530ms/step - loss: 193.2374 - mean_absolute_error: 10.5516 - val_loss: 131.6181 - val_mean_absolute_error: 10.9393\n"
     ]
    }
   ],
   "source": [
    "from cgmcore import modelutils\n",
    "\n",
    "input_shape = (32, 32, 32)\n",
    "output_size = 1\n",
    "model_voxnet = modelutils.create_voxnet_model_homepage(input_shape, output_size)\n",
    "model_voxnet.summary()\n",
    "\n",
    "# Compile the model.\n",
    "model_voxnet.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "# Train the model.\n",
    "history = model_voxnet.fit_generator(\n",
    "    generator_voxelgrids_train,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=epochs,\n",
    "    validation_data=generator_voxelgrids_validate,\n",
    "    validation_steps=validation_steps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving everything.\n",
    "\n",
    "This saves the model, its history and the training-details to some output directory. The created artifacts can later be uses in order to compare different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model and history...\n",
      "Saved model to./20181105-1134-voxnet-model.h5\n",
      "Saved model weights to./20181105-1134-voxnet-model-weights.h5\n",
      "Saved training details to./20181105-1134-voxnet-details.p\n",
      "Saved history to./20181105-1134-voxnet-history.p\n"
     ]
    }
   ],
   "source": [
    "output_path = \".\"\n",
    "\n",
    "modelutils.save_model_and_history(output_path, model_voxnet, history, training_details, \"voxnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
