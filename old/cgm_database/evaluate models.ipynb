{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/datathon/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import dbutils\n",
    "from datetime import date\n",
    "from time import mktime\n",
    "import calendar\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from keras import models\n",
    "import progressbar\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from cgmcore import modelutils\n",
    "from cgmcore import utils\n",
    "\n",
    "main_connector = dbutils.connect_to_main_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the PCD data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag 2018-9 has 2063 PCDs.\n",
      "Tag 2018-10 has 1871 PCDs.\n",
      "Tag 2018-11 has 385 PCDs.\n",
      "Tag 2018-12 has 443 PCDs.\n",
      "Tag all-data has 4762 PCDs.\n",
      "\n",
      "5 megabatches to check.\n"
     ]
    }
   ],
   "source": [
    "# This is the main variable.\n",
    "pcd_megabatches = []\n",
    "\n",
    "# The table to query.\n",
    "data_table = \"pointcloud_data\"\n",
    "\n",
    "# The values of the measurents-table that should appear in the results.\n",
    "values = [\"height_cms\"]\n",
    "values = [\"measurements.\" + value for value in values]\n",
    "values = \", \".join(values)\n",
    "\n",
    "\n",
    "for year in [2018, 2019]:\n",
    "    for month in range(1, 13):\n",
    "        \n",
    "        # Getting the start.\n",
    "        start_day = 1\n",
    "        start_date = date(year, month, start_day)\n",
    "        start_timestamp = str(1000 * int(mktime(start_date.timetuple())))\n",
    "        \n",
    "        # Getting the end.\n",
    "        _, end_day = calendar.monthrange(year, month)\n",
    "        end_date = date(year, month, end_day)\n",
    "        end_timestamp = str(1000 * int(mktime(end_date.timetuple())))\n",
    "\n",
    "        # Compose an SQL-statement.\n",
    "        sql_statement = \"\"\n",
    "        sql_statement += \"SELECT {}.path, {}\".format(data_table, values)\n",
    "        sql_statement += \" FROM {}\".format(data_table)\n",
    "        sql_statement += \" INNER JOIN measurements ON {}.measurement_id=measurements.id\".format(data_table)\n",
    "        sql_statement += \" WHERE measurements.type=\\'manual\\'\"\n",
    "        sql_statement += \" AND measurements.timestamp >= {}\".format(start_timestamp)\n",
    "        sql_statement += \" AND measurements.timestamp <= {}\".format(end_timestamp)\n",
    "        sql_statement += \" AND timestamp <= {}\".format(end_timestamp)\n",
    "        results = main_connector.execute(sql_statement, fetch_all=True)\n",
    "        if len(results) != 0:\n",
    "            pcd_megabatches.append((f\"{year}-{month}\", results))\n",
    "\n",
    "all_results = []\n",
    "for _, results in pcd_megabatches:\n",
    "    all_results.extend(results)\n",
    "pcd_megabatches.append((\"all-data\", all_results))\n",
    "\n",
    "    \n",
    "for tag, results in pcd_megabatches:\n",
    "    print(\"Tag {} has {} PCDs.\".format(tag, len(results)))\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"{} megabatches to check.\".format(len(pcd_megabatches)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 models\n"
     ]
    }
   ],
   "source": [
    "# Getting all the model paths.\n",
    "models_root_path = \"/whhdata/models\"\n",
    "model_paths = sorted(glob.glob(os.path.join(models_root_path, \"*.h5\")))\n",
    "model_paths = [model_path for model_path in model_paths if model_path.endswith(\"-model-weights.h5\") == False]\n",
    "print(\"Found {} models\".format(len(model_paths)))\n",
    "\n",
    "# Load one spare point net model.\n",
    "point_net_model = modelutils.create_point_net((30000, 3), 1, hidden_sizes = [512, 256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating models against mega-batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating/whhdata/models/20181026-0710-voxnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181029-1312-voxnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181029-1314-voxnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181029-1801-pointnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181031-1201-pointnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181031-1636-pointnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181031-2038-pointnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181101-1444-pointnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181101-1643-pointnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181101-2145-pointnet-model.h5...\n",
      "Skipped.\n",
      "Evaluating/whhdata/models/20181104-0039-2dCNN-model.h5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                               \r",
      "\r",
      "N/A% (0 of 2063) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3) (1,)\n",
      "2018-9: 2063 PCDs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99% (2055 of 2063) |################### | Elapsed Time: 0:16:56 ETA:   0:00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot reshape array of size 0 into shape (0,newaxis)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-593bfc11e828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# Evaluate the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;31m# TODO put this to a database.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mevaluation_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Results for {model_path}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluation_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-593bfc11e828>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-593bfc11e828>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mpcd_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pcd_as_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mrgb_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpointcloud_to_rgb_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpcd_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"vertical\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m                 \u001b[0mx_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0my_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/datathon/lib/python3.6/site-packages/cgmcore/utils.py\u001b[0m in \u001b[0;36mpointcloud_to_rgb_map\u001b[0;34m(original_pointcloud, target_width, target_height, scale_factor, axis)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;31m# Get indices and counts.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointcloud\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# Get unique pixel coordinates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/anaconda/envs/datathon/lib/python3.6/site-packages/numpy/lib/arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Must reshape to a contiguous 2D array for this to work...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0morig_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f{i}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0,newaxis)"
     ]
    }
   ],
   "source": [
    "#batch_size = 128\n",
    "\n",
    "model_load_errors = 0\n",
    "\n",
    "# Routine for loading models.\n",
    "def load_model(model_path):\n",
    "    # Try to load the model.\n",
    "    try:\n",
    "        model = models.load_model(model_path)\n",
    "    except ValueError:\n",
    "        # Error. Could be a problem with pointnet, which needs to be loaded via weights.\n",
    "        try:\n",
    "            model = point_net_model\n",
    "            model.load_weights(model_path.replace(\"-model.h5\", \"-model-weights.h5\"))\n",
    "        except Exception as e:\n",
    "            # All hope is lost.\n",
    "            print(e)\n",
    "            print(\"Error loading model.\")\n",
    "            return None\n",
    "    return model\n",
    " \n",
    "# Evaluating models.\n",
    "def evaluate_model(model):\n",
    "    evaluation_results = []\n",
    "    \n",
    "    input_shape = model.inputs[0].shape[1:]\n",
    "    model_type = \"\"\n",
    "    if len(input_shape) == 3 and input_shape == (32, 32, 32):\n",
    "        model_type =\"voxnet\"\n",
    "    elif len(input_shape) == 3 and input_shape[2] == 3:\n",
    "        model_type =\"rgb\"\n",
    "        target_width = int(model.inputs[0].shape[1])\n",
    "        target_height = int(model.inputs[0].shape[2])\n",
    "    elif len(input_shape) == 2 and input_shape == (30000, 3):\n",
    "        model_type =\"pointcloud\"\n",
    "    else:\n",
    "        print(\"Unexpected:\", input_shape)\n",
    "        \n",
    "    output_shape = model.outputs[0].shape[1:]\n",
    "    print(input_shape, output_shape)\n",
    "    \n",
    "    for tag, samples in pcd_megabatches:\n",
    "        print(\"{}: {} PCDs.\".format(tag, len(samples)))\n",
    "        \n",
    "        x_input = []\n",
    "        y_output = []\n",
    "        bar = progressbar.ProgressBar(max_value=len(samples))\n",
    "        for index, (path, target) in enumerate(samples):\n",
    "            bar.update(index)\n",
    "            try:\n",
    "                pcd_array = utils.load_pcd_as_ndarray(path)\n",
    "                rgb_map = utils.pointcloud_to_rgb_map(pcd_array, target_width=target_width, target_height=target_height, scale_factor=1.0, axis=\"vertical\")\n",
    "                x_input.append(rgb_map)\n",
    "                y_output.append(target)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                raise e\n",
    "        bar.finish()  \n",
    "        \n",
    "        x_input = np.array(x_input)\n",
    "        y_output = np.array(y_output)\n",
    "\n",
    "        mse, mae = model.evaluate(x_input, y_output)\n",
    "        print(tag, mse, mae)\n",
    "        evaluation_results.append((tag, mse, mae))\n",
    "    return evaluation_results\n",
    "        \n",
    "        \n",
    "# Loop through all models.\n",
    "for model_index, model_path in enumerate(model_paths):\n",
    "    print(f\"Evaluating{model_path}...\")\n",
    "    \n",
    "    # Skip voxnets and pointnets (debugging).\n",
    "    if \"voxnet\" in model_path or \"pointnet\" in model_path:\n",
    "        print(\"Skipped.\")\n",
    "        continue\n",
    "    \n",
    "    # Attempt to load the model.\n",
    "    model = load_model(model_path)\n",
    "    if model == None:\n",
    "        model_load_errors += 1\n",
    "        continue\n",
    "    \n",
    "    # Evaluate the model.\n",
    "    # TODO put this to a database.\n",
    "    evaluation_results = evaluate_model(model)\n",
    "    print(f\"Results for {model_path}:\")\n",
    "    for tag, mse, mae in evaluation_results:\n",
    "        print(f\"{tag} mse: {mse} mae: {mae}\")\n",
    "\n",
    "    del model\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "print(f\"{model_load_errors}/{len(model_paths)} models could not be loaded due to errors.\")\n",
    "    #print(\"Evaluating model \\\"{}\\\"...\".format(model_path))\n",
    "    #for batch_index, index in enumerate(range(0, len(results), batch_size)):\n",
    "    #    print(batch_index, index, index + batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
