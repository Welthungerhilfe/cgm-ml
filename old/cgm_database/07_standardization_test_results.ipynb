{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from cgmcore import modelutils, utils\n",
    "import dbutils\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mkdir_if_not_exists(path_to_create):\n",
    "    if os.path.exists(path_to_create) == False:\n",
    "        os.mkdir(path_to_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the models.\n",
    "db_connector = dbutils.connect_to_main_database()\n",
    "select_sql_statement = \"SELECT DISTINCT(type) FROM artifact_quality;\"\n",
    "types = db_connector.execute(select_sql_statement, fetch_all=True)\n",
    "models_in_database = [t[0] for t in types if len(t[0]) > 20 and \"height\" in t[0]]\n",
    "\n",
    "selected_model = None\n",
    "\n",
    "@interact(models=models_in_database)\n",
    "def select_model(models):\n",
    "    global selected_model\n",
    "    selected_model = models\n",
    "    print(\"Selected model '{}'.\".format(selected_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_path = \"/whhdata/models/{0}/{0}-pointnet-model-weights.h5\".format(selected_model)\n",
    "\n",
    "def load_model(model_path):\n",
    "\n",
    "    input_shape = (10000, 3)\n",
    "    output_size = 1\n",
    "    model = modelutils.create_point_net(input_shape, output_size, hidden_sizes = [512, 256, 128])\n",
    "    model.load_weights(model_path)\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    return model \n",
    "\n",
    "print(\"Loading model...\")\n",
    "model = load_model(model_path)\n",
    "print(\"Model loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the paths of the scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob2 as glob\n",
    "import os\n",
    "\n",
    "measurements_path = \"/localssd/20190724_Standardization_AAH/\"\n",
    "\n",
    "scan_paths = glob.glob(os.path.join(measurements_path, \"*\"))\n",
    "scan_paths = sorted(scan_paths)\n",
    "\n",
    "print(\"Scans to be used:\")\n",
    "print(\"\\n\".join(scan_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 1000)\n",
    "pose_types = [\"100\", \"101\", \"102\", \"200\", \"201\", \"202\"]\n",
    "\n",
    "#@interact(scan_path=scan_paths)\n",
    "def render(scan_path, file_path=None):\n",
    "    rows = []\n",
    "    \n",
    "    # Get all PCDs.\n",
    "    pcd_paths = glob.glob(os.path.join(scan_path, \"**\", \"*.pcd\"))\n",
    "    if len(pcd_paths) == 0:\n",
    "        print(\"Could not find any PCDs at {}.\".format(scan_path))\n",
    "        return\n",
    "    print(\"Found {} PCDs for {}...\".format(len(pcd_paths), scan_path))\n",
    "    print()\n",
    "    \n",
    "    #pcd_paths_with_type = []\n",
    "    #for pcd_path in pcd_paths:\n",
    "    #    pose_type = pcd_path.split(\"/\")[-1].split(\"_\")[-2]\n",
    "    #    pcd_paths_with_type.append((pcd_path, pose_type))\n",
    "    #del pcd_paths\n",
    "    \n",
    "    # Load the artifact and evaluate.\n",
    "    print(\"Loading PCDs. This might take a while...\")\n",
    "    pcd_arrays = []\n",
    "    for pcd_path in tqdm(pcd_paths):\n",
    "        pcd_array = utils.load_pcd_as_ndarray(pcd_path)\n",
    "        pcd_array = utils.subsample_pointcloud(pcd_array, 10000)\n",
    "        pcd_arrays.append(pcd_array)\n",
    "    pcd_arrays = np.array(pcd_arrays)\n",
    "    \n",
    "    # Predict on all.\n",
    "    print(\"Predicting...\")\n",
    "    predictions = model.predict(pcd_arrays, verbose=1)\n",
    "    \n",
    "    # Just check.\n",
    "    assert len(pcd_paths) == len(predictions)\n",
    "    \n",
    "    # Prepare data.frame.\n",
    "    for pcd_path, prediction in zip(pcd_paths, predictions):\n",
    "        rows.append((pcd_path, prediction[0]))\n",
    "\n",
    "    # Create a data-frame.\n",
    "    print(\"Creating data-frame...\")\n",
    "    df = pd.DataFrame.from_records(rows, columns=[\"path\", \"predicted target\"])\n",
    "    if file_path != None:\n",
    "        df.to_csv(file_path + \".csv\")\n",
    "    else:\n",
    "        display(df)\n",
    "    \n",
    "    # Render the barchart.\n",
    "    print(\"Rendering plot...\")\n",
    "    x_values = []\n",
    "    colors = []\n",
    "    for index, pcd_path in enumerate(pcd_paths):\n",
    "        if \"_100_\" in pcd_path:\n",
    "            x_values.append(\"{}-100\".format(index + 1))\n",
    "            colors.append(\"C0\")\n",
    "        elif \"_101_\" in pcd_path:\n",
    "            x_values.append(\"{}-101\".format(index + 1))\n",
    "            colors.append(\"C1\")\n",
    "        elif \"_102_\" in pcd_path:\n",
    "            x_values.append(\"{}-102\".format(index + 1))\n",
    "            colors.append(\"C3\")\n",
    "        elif \"_200_\" in pcd_path:\n",
    "            x_values.append(\"{}-200\".format(index + 1))\n",
    "            colors.append(\"C4\")\n",
    "        elif \"_201_\" in pcd_path:\n",
    "            x_values.append(\"{}-201\".format(index + 1))\n",
    "            colors.append(\"C5\")\n",
    "        elif \"_202_\" in pcd_path:\n",
    "            x_values.append(\"{}-202\".format(index + 1))\n",
    "            colors.append(\"C6\") \n",
    "        else:\n",
    "            print(pcd_Path)\n",
    "            assert False\n",
    "    bottom_value = 60\n",
    "    x = list(range(len(predictions)))\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.bar(x, [prediction[0] - bottom_value for prediction in predictions], color=colors, bottom=bottom_value)\n",
    "    #plt.xticks(x, x_values, rotation='vertical')\n",
    "    plt.title(scan_path.split(\"/\")[-1])\n",
    "    if file_path != None:\n",
    "        plt.savefig(file_path + \".png\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Create some folders.\n",
    "root_path = \"/whhdata/standardization_test_results\"\n",
    "mkdir_if_not_exists(root_path)\n",
    "model_path = os.path.join(root_path, selected_model)\n",
    "mkdir_if_not_exists(model_path)\n",
    "\n",
    "# Process each scan.\n",
    "for scan_path in scan_paths:\n",
    "    qr_code = scan_path.split(\"/\")[-1]\n",
    "    print(\"Processing {}...\".format(qr_code))\n",
    "    output_path = os.path.join(model_path, qr_code)\n",
    "    render(scan_path, output_path)\n",
    "    \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
