{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README.\n",
    "\n",
    "This notebook is the entrypoint for Azure ML enabled training.\n",
    "In its essence, it connects to Azure ML, makes sure that everything is ready over there, and starts the training.\n",
    "To that end, this notebook gathers all necessary sourcecodes in a temp-folder, which will be pushed to Azure ML for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'code.constants'; 'code' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-554a33887e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# idk why this is not working\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mREPO_DIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m#from code.train_util import copy_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#from code.config import CONFIG, DATASET_MODE_MOUNT, DATASET_MODE_DOWNLOAD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'code.constants'; 'code' is not a package"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "#import urllib\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from azureml.core import Workspace, Dataset, Experiment, Run\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "from azureml.train.dnn import TensorFlow\n",
    "\n",
    "# idk why this is not working\n",
    "from code.constants import REPO_DIR\n",
    "#from code.train_util import copy_dir\n",
    "#from code.config import CONFIG, DATASET_MODE_MOUNT, DATASET_MODE_DOWNLOAD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting screws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"anon-depthmap-95k\"\n",
    "experiment_name = \"q3-cnndepthmap-resnet-height-95k\"\n",
    "#tags = {} Q: DO I NEED THIS HERE?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create temp folder and copy code.\n",
    "\n",
    "Here you have to be very precise, which code to copy.\n",
    "And most importantly, which code NOT to copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'copy_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8404037dfdbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcode_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"src\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtemp_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"temp_train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcopy_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'*.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcopy_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREPO_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"src/common\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"temp_common\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'*/*.py'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_touch_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'copy_dir' is not defined"
     ]
    }
   ],
   "source": [
    "#new\n",
    "code_dir = Path(\"src\")\n",
    "temp_path = Path(\"temp_train\")\n",
    "copy_dir(src=code_dir, tgt=temp_path, glob_pattern='*.py')\n",
    "copy_dir(src=REPO_DIR / \"src/common\", tgt=temp_path / \"temp_common\", glob_pattern='*/*.py', should_touch_init=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "#print(\"Creating temp folder...\")\n",
    "#temp_path = \"temp_train\"\n",
    "#if os.path.exists(temp_path):\n",
    "#    shutil.rmtree(temp_path)\n",
    "#os.mkdir(temp_path)\n",
    "#\n",
    "#print(\"Copying files...\")\n",
    "#shutil.copy(os.path.join(\"code\", \"train.py\"), temp_path)\n",
    "#shutil.copy(os.path.join(\"code\", \"model.py\"), temp_path)\n",
    "#shutil.copy(os.path.join(\"code\", \"preprocessing.py\"), temp_path)\n",
    "#shutil.copy(os.path.join(\"code\", \"utils.py\"), temp_path)\n",
    "#print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to azure workspace.\n",
    "\n",
    "Make sure that you have a config.json file with the keys subscription_id, resource_group, and cgm-ml-dev. Either here (not so nice) or in a parent folder (okay but not perfect), or in the root folder of this repo (way to go)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = Workspace.from_config()\n",
    "workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the experiment.\n",
    "\n",
    "- You should always arrange all your runs in an experiment.\n",
    "- Create at least one experiment per sprint.\n",
    "- Make sure that the name of the experiment reflects the sprint number.\n",
    "- On top of that you could also add other tokens to the name. For example network architecture, dataset name, and/or targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(workspace=workspace, name=experiment_name)\n",
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find/create a compute target.\n",
    "\n",
    "Connects to a compute cluster on Azure ML.\n",
    "If the compute cluster does not exist, it will be created.\n",
    "\n",
    "Note: Usually computer clusters autoscale. This means that new nodes are created when necessary. And unused VMs will be shut down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = \"gpu-cluster\"\n",
    "\n",
    "# Compute cluster exists. Just connect to it.\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=workspace, name=cluster_name)\n",
    "    print(\"Found existing compute target.\")\n",
    "\n",
    "# Compute cluster does not exist. Create one.    \n",
    "except ComputeTargetException:\n",
    "    print(\"Creating a new compute target...\")\n",
    "    compute_config = AmlCompute.provisioning_configuration(\n",
    "        vm_size='Standard_NC6', \n",
    "        max_nodes=4\n",
    "    )\n",
    "    compute_target = ComputeTarget.create(workspace, cluster_name, compute_config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "compute_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataset for training.\n",
    "\n",
    "Here you specify which dataset to use.\n",
    "\n",
    "Note: Double check on Azure ML that you are using the right one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = workspace.datasets[dataset_name]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Push the training source code to Azure.\n",
    "\n",
    "Creates an estimator (a template for a compute cluster node) and pushes it to the compute cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CONFIG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6bd119307156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscript_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34mf\"--{k}\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscript_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CONFIG' is not defined"
     ]
    }
   ],
   "source": [
    "script_params = {f\"--{k}\": v for k, v in CONFIG.items()}\n",
    "script_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_env_name = \"cgm-env\"\n",
    "\n",
    "ENV_EXISTS = True\n",
    "if ENV_EXISTS:\n",
    "    cgm_env = Environment.get(workspace=workspace, name=curated_env_name)\n",
    "else:\n",
    "    cgm_env = Environment.from_conda_specification(name=curated_env_name, file_path=REPO_DIR / \"environment_train.yml\")\n",
    "    cgm_env.docker.enabled = True\n",
    "    cgm_env.docker.base_image = 'mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04'\n",
    "    # cgm_env.register(workspace)  # Please be careful not to overwrite existing environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.DATASET_MODE == DATASET_MODE_MOUNT:\n",
    "    dataset_argument = dataset.as_named_input('cgm_dataset').as_mount()\n",
    "elif CONFIG.DATASET_MODE == DATASET_MODE_DOWNLOAD:\n",
    "    dataset_argument = dataset.as_named_input('cgm_dataset').as_download()\n",
    "else:\n",
    "    raise Exception(\"Please specify DATASET_MODE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ScriptRunConfig\n",
    "script_run_config = ScriptRunConfig(source_directory=temp_path,\n",
    "                                    compute_target=compute_target,\n",
    "                                    script='train.py',\n",
    "                                    arguments=[dataset_argument] + [str(item) for sublist in script_params.items() for item in sublist],\n",
    "                                    environment=cgm_env,\n",
    ")\n",
    "\n",
    "# Set compute target.\n",
    "script_run_config.run_config.target = compute_target\n",
    "\n",
    "# Run the experiment.\n",
    "run = experiment.submit(config=script_run_config, tags=tags)\n",
    "\n",
    "# Show run.\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old TensorFlow.get_supported_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# old\n",
    "# Specify pip packages here.\n",
    "#pip_packages = [\n",
    "#    \"azureml-dataprep[fuse,pandas]\",\n",
    "#    \"glob2\",\n",
    "#    \"opencv-python\",\n",
    "#    \"matplotlib\",\n",
    "#    \"tensorflow-addons==0.11.2\",\n",
    "#    \"bunch==1.0.1\",\n",
    "#]\n",
    "#\n",
    "#script_params = {\n",
    "#    \"--split_seed\": 666,\n",
    "#    \"--target_size\": \"180x240\",\n",
    "#    \"--epochs\": 1000,\n",
    "#    \"--batch_size\": 64,\n",
    "#    \"--normalization_value\": 7.5,\n",
    "#    \"--res_blocks\": \"1,1,1,1\",\n",
    "#    \"--dropouts\": \"0.2,0.3,0.4,0.5\",\n",
    "#    \"--comment\": \"ResNet on 95K data. With dropout.\"\n",
    "#}\n",
    "#\n",
    "## Create the estimator.\n",
    "#estimator = TensorFlow(\n",
    "#    source_directory=temp_path,\n",
    "#    compute_target=compute_target,\n",
    "#    entry_script=\"train.py\",\n",
    "#    use_gpu=True,\n",
    "#    framework_version=\"2.0\",\n",
    "#    inputs=[dataset.as_named_input(\"dataset\").as_mount()],\n",
    "#    pip_packages=pip_packages,\n",
    "#    script_params=script_params\n",
    "#)\n",
    "#\n",
    "## Set compute target.\n",
    "#estimator.run_config.target = compute_target\n",
    "#\n",
    "## Run the experiment.\n",
    "#run = experiment.submit(estimator)\n",
    "#\n",
    "## Show outputs.\n",
    "#run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete temp folder.\n",
    "\n",
    "After all code has been pushed to Azure ML, the temp folder will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
